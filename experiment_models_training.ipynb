{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training\n",
    "\n",
    "This notebook can be used to train the models used for the replication experiment. The notebook makes heavy use of predefined configuration files that describe the parameter setting of each model.\n",
    "\n",
    "**To replace the pretrained models in the replication study** you need to copy the trained model from `checkpoints` to `Explanation/models/pretrained/<_model>/<_dataset>`. Where \\_model and \\_dataset are defined as in the code below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = 'cpu'\n",
    "import numpy as np\n",
    "from ExplanationEvaluation.configs.selector import Selector\n",
    "from ExplanationEvaluation.tasks.training import meta_train_node, meta_train_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "_dataset = 'bacommunity' # One of: bashapes, bacommunity, treecycles, treegrids, ba2motifs, mutag\n",
    "_folder = 'replication'\n",
    "_model = 'gnn'\n",
    "config_path = f\"./ExplanationEvaluation/configs/{_folder}/models/model_{_model}_{_dataset}.json\"\n",
    "\n",
    "config = Selector(config_path)\n",
    "extension = (_folder == 'extension')\n",
    "\n",
    "config = Selector(config_path).args\n",
    "\n",
    "torch.manual_seed(config.model.seed)\n",
    "torch.cuda.manual_seed(config.model.seed)\n",
    "np.random.seed(config.model.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading syn1 dataset\n",
      "NodeGCN(\n",
      "  (conv1): GCNConv(10, 20)\n",
      "  (relu1): ReLU()\n",
      "  (conv2): GCNConv(20, 20)\n",
      "  (relu2): ReLU()\n",
      "  (conv3): GCNConv(20, 20)\n",
      "  (relu3): ReLU()\n",
      "  (lin): Linear(in_features=60, out_features=4, bias=True)\n",
      ")\n",
      "Epoch: 0, train_acc: 0.1196, val_acc: 0.0714, train_loss: 1.4274\n",
      "Val improved\n",
      "Epoch: 1, train_acc: 0.2179, val_acc: 0.3143, train_loss: 1.4113\n",
      "Val improved\n",
      "Epoch: 2, train_acc: 0.2179, val_acc: 0.3143, train_loss: 1.3936\n",
      "Epoch: 3, train_acc: 0.4464, val_acc: 0.3143, train_loss: 1.3791\n",
      "Epoch: 4, train_acc: 0.4464, val_acc: 0.3143, train_loss: 1.3657\n",
      "Epoch: 5, train_acc: 0.4464, val_acc: 0.3143, train_loss: 1.3545\n",
      "Epoch: 6, train_acc: 0.4464, val_acc: 0.3143, train_loss: 1.3452\n",
      "Epoch: 7, train_acc: 0.4464, val_acc: 0.3143, train_loss: 1.3377\n",
      "Epoch: 8, train_acc: 0.4464, val_acc: 0.3143, train_loss: 1.3304\n",
      "Epoch: 9, train_acc: 0.4464, val_acc: 0.3143, train_loss: 1.3240\n",
      "Epoch: 10, train_acc: 0.4464, val_acc: 0.3143, train_loss: 1.3181\n",
      "Epoch: 11, train_acc: 0.4464, val_acc: 0.3143, train_loss: 1.3127\n",
      "Epoch: 12, train_acc: 0.4464, val_acc: 0.3143, train_loss: 1.3074\n",
      "Epoch: 13, train_acc: 0.4464, val_acc: 0.3143, train_loss: 1.3027\n",
      "Epoch: 14, train_acc: 0.4464, val_acc: 0.3143, train_loss: 1.2984\n",
      "Epoch: 15, train_acc: 0.4464, val_acc: 0.3143, train_loss: 1.2946\n",
      "Epoch: 16, train_acc: 0.4464, val_acc: 0.3143, train_loss: 1.2911\n",
      "Epoch: 17, train_acc: 0.4464, val_acc: 0.3143, train_loss: 1.2880\n",
      "Epoch: 18, train_acc: 0.4464, val_acc: 0.3143, train_loss: 1.2856\n",
      "Epoch: 19, train_acc: 0.4464, val_acc: 0.3143, train_loss: 1.2835\n",
      "Epoch: 20, train_acc: 0.4464, val_acc: 0.3143, train_loss: 1.2818\n",
      "Epoch: 21, train_acc: 0.4464, val_acc: 0.3143, train_loss: 1.2801\n",
      "Epoch: 22, train_acc: 0.4464, val_acc: 0.3143, train_loss: 1.2787\n",
      "Epoch: 23, train_acc: 0.4464, val_acc: 0.3143, train_loss: 1.2778\n",
      "Epoch: 24, train_acc: 0.4464, val_acc: 0.3143, train_loss: 1.2770\n",
      "Epoch: 25, train_acc: 0.4464, val_acc: 0.3143, train_loss: 1.2762\n",
      "Epoch: 26, train_acc: 0.4464, val_acc: 0.3143, train_loss: 1.2755\n",
      "Epoch: 27, train_acc: 0.4464, val_acc: 0.3143, train_loss: 1.2747\n",
      "Epoch: 28, train_acc: 0.4464, val_acc: 0.3143, train_loss: 1.2741\n",
      "Epoch: 29, train_acc: 0.4464, val_acc: 0.3143, train_loss: 1.2735\n",
      "Epoch: 30, train_acc: 0.4464, val_acc: 0.3143, train_loss: 1.2727\n",
      "Epoch: 31, train_acc: 0.4464, val_acc: 0.3143, train_loss: 1.2718\n",
      "Epoch: 32, train_acc: 0.4464, val_acc: 0.3143, train_loss: 1.2710\n",
      "Epoch: 33, train_acc: 0.4464, val_acc: 0.3143, train_loss: 1.2699\n",
      "Epoch: 34, train_acc: 0.4464, val_acc: 0.3143, train_loss: 1.2691\n",
      "Epoch: 35, train_acc: 0.4464, val_acc: 0.3143, train_loss: 1.2685\n",
      "Epoch: 36, train_acc: 0.4464, val_acc: 0.3143, train_loss: 1.2675\n",
      "Epoch: 37, train_acc: 0.4464, val_acc: 0.3143, train_loss: 1.2662\n",
      "Epoch: 38, train_acc: 0.4464, val_acc: 0.3143, train_loss: 1.2654\n",
      "Epoch: 39, train_acc: 0.4464, val_acc: 0.3143, train_loss: 1.2642\n",
      "Epoch: 40, train_acc: 0.4464, val_acc: 0.3143, train_loss: 1.2629\n",
      "Epoch: 41, train_acc: 0.4464, val_acc: 0.3143, train_loss: 1.2615\n",
      "Epoch: 42, train_acc: 0.4464, val_acc: 0.3143, train_loss: 1.2600\n",
      "Epoch: 43, train_acc: 0.4464, val_acc: 0.3143, train_loss: 1.2581\n",
      "Epoch: 44, train_acc: 0.4464, val_acc: 0.3143, train_loss: 1.2554\n",
      "Epoch: 45, train_acc: 0.4464, val_acc: 0.3143, train_loss: 1.2534\n",
      "Epoch: 46, train_acc: 0.4464, val_acc: 0.3143, train_loss: 1.2503\n",
      "Epoch: 47, train_acc: 0.4464, val_acc: 0.3143, train_loss: 1.2465\n",
      "Epoch: 48, train_acc: 0.4464, val_acc: 0.3143, train_loss: 1.2424\n",
      "Epoch: 49, train_acc: 0.4464, val_acc: 0.3143, train_loss: 1.2379\n",
      "Epoch: 50, train_acc: 0.4464, val_acc: 0.3143, train_loss: 1.2304\n",
      "Epoch: 51, train_acc: 0.4464, val_acc: 0.3143, train_loss: 1.2231\n",
      "Epoch: 52, train_acc: 0.4464, val_acc: 0.3143, train_loss: 1.2148\n",
      "Epoch: 53, train_acc: 0.4464, val_acc: 0.3143, train_loss: 1.2032\n",
      "Epoch: 54, train_acc: 0.4464, val_acc: 0.3143, train_loss: 1.1895\n",
      "Epoch: 55, train_acc: 0.4464, val_acc: 0.3143, train_loss: 1.1759\n",
      "Epoch: 56, train_acc: 0.4464, val_acc: 0.3143, train_loss: 1.1497\n",
      "Epoch: 57, train_acc: 0.4464, val_acc: 0.3143, train_loss: 1.1264\n",
      "Epoch: 58, train_acc: 0.5982, val_acc: 0.5571, train_loss: 1.0849\n",
      "Val improved\n",
      "Epoch: 59, train_acc: 0.6589, val_acc: 0.6143, train_loss: 1.0923\n",
      "Val improved\n",
      "Epoch: 60, train_acc: 0.5875, val_acc: 0.5571, train_loss: 1.0718\n",
      "Epoch: 61, train_acc: 0.4482, val_acc: 0.3143, train_loss: 1.0238\n",
      "Epoch: 62, train_acc: 0.4464, val_acc: 0.3143, train_loss: 1.0552\n",
      "Epoch: 63, train_acc: 0.5518, val_acc: 0.4714, train_loss: 1.0751\n",
      "Epoch: 64, train_acc: 0.6607, val_acc: 0.6143, train_loss: 1.0251\n",
      "Epoch: 65, train_acc: 0.6589, val_acc: 0.6143, train_loss: 1.0409\n",
      "Epoch: 66, train_acc: 0.4482, val_acc: 0.3143, train_loss: 1.0616\n",
      "Epoch: 67, train_acc: 0.6304, val_acc: 0.6000, train_loss: 1.0391\n",
      "Epoch: 68, train_acc: 0.6464, val_acc: 0.6143, train_loss: 0.9974\n",
      "Epoch: 69, train_acc: 0.6571, val_acc: 0.6143, train_loss: 0.9640\n",
      "Epoch: 70, train_acc: 0.6250, val_acc: 0.6000, train_loss: 0.9413\n",
      "Epoch: 71, train_acc: 0.4839, val_acc: 0.3571, train_loss: 0.9786\n",
      "Epoch: 72, train_acc: 0.6571, val_acc: 0.6143, train_loss: 0.9421\n",
      "Epoch: 73, train_acc: 0.6589, val_acc: 0.6143, train_loss: 0.9125\n",
      "Epoch: 74, train_acc: 0.6554, val_acc: 0.6143, train_loss: 0.9099\n",
      "Epoch: 75, train_acc: 0.6411, val_acc: 0.6143, train_loss: 0.8972\n",
      "Epoch: 76, train_acc: 0.6554, val_acc: 0.6143, train_loss: 0.8806\n",
      "Epoch: 77, train_acc: 0.6268, val_acc: 0.6000, train_loss: 0.8604\n",
      "Epoch: 78, train_acc: 0.5875, val_acc: 0.5286, train_loss: 0.8962\n",
      "Epoch: 79, train_acc: 0.6589, val_acc: 0.6143, train_loss: 0.8770\n",
      "Epoch: 80, train_acc: 0.6589, val_acc: 0.6143, train_loss: 0.8553\n",
      "Epoch: 81, train_acc: 0.6518, val_acc: 0.6143, train_loss: 0.8443\n",
      "Epoch: 82, train_acc: 0.6411, val_acc: 0.6000, train_loss: 0.8314\n",
      "Epoch: 83, train_acc: 0.6518, val_acc: 0.6143, train_loss: 0.8170\n",
      "Epoch: 84, train_acc: 0.6589, val_acc: 0.6143, train_loss: 0.8041\n",
      "Epoch: 85, train_acc: 0.6571, val_acc: 0.6143, train_loss: 0.8037\n",
      "Epoch: 86, train_acc: 0.6411, val_acc: 0.6143, train_loss: 0.8002\n",
      "Epoch: 87, train_acc: 0.6518, val_acc: 0.6143, train_loss: 0.7934\n",
      "Epoch: 88, train_acc: 0.6589, val_acc: 0.6143, train_loss: 0.7765\n",
      "Epoch: 89, train_acc: 0.6589, val_acc: 0.6143, train_loss: 0.7724\n",
      "Epoch: 90, train_acc: 0.6429, val_acc: 0.6143, train_loss: 0.7686\n",
      "Epoch: 91, train_acc: 0.6518, val_acc: 0.6143, train_loss: 0.7632\n"
     ]
    }
   ],
   "source": [
    "_dataset = config.model.dataset\n",
    "_explainer = config.model.paper\n",
    "\n",
    "if _dataset[:3] == \"syn\":\n",
    "    meta_train_node(_dataset, _explainer, config.model, device)\n",
    "elif _dataset == \"ba2\" or _dataset == \"mutag\":\n",
    "    meta_train_graph(_dataset, _explainer, config.model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
